{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 134\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m    133\u001b[0m model1 \u001b[38;5;241m=\u001b[39m model_fnn\n\u001b[1;32m--> 134\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m()\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# visualkeras.layered_view(model1)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "import visualkeras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications as LayerApp\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import absl.logging\n",
    "\n",
    "class CustomCNN(Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Add L2 regularization to the convolutional layers\n",
    "        #self.conv1 = Conv1D(32, 3, activation='relu', padding='same', kernel_regularizer=l2(0.00001))\n",
    "        self.conv1 = Conv1D(32, 3, activation='relu', padding='same')\n",
    "        #self.bn1 = BatchNormalization()\n",
    "        self.pool1 = MaxPooling1D(2)\n",
    "        #self.dropout1 = Dropout(0.2)\n",
    "\n",
    "        #self.conv2 = Conv1D(64, 3, activation='relu', padding='same', kernel_regularizer=l2(0.00001))\n",
    "        self.conv2 = Conv1D(64, 3, activation='relu', padding='same')\n",
    "        #self.bn2 = BatchNormalization()\n",
    "        #self.pool2 = MaxPooling1D(2)\n",
    "        #self.dropout2 = Dropout(0.2)\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(256, activation='relu')\n",
    "        self.dropout3 = Dropout(0.2)\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dense3 = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # 시퀀스 길이 대신 특징 차원에 대한 차원 추가\n",
    "        inputs = tf.expand_dims(inputs, axis=-1)\n",
    "        x = self.conv1(inputs)\n",
    "        #x = self.bn1(x, training=training)\n",
    "        x = self.pool1(x)\n",
    "        #x = self.dropout1(x, training=training)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        #x = self.bn2(x, training=training)\n",
    "        #x = self.pool2(x)\n",
    "        #x = self.dropout2(x, training=training)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout3(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "class FNN(Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(FNN, self).__init__()\n",
    "        self.dense1 = Dense(256, activation='relu')\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dense3 = Dense(256, activation='relu')\n",
    "        self.dense_last = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # 시퀀스 길이 대신 특징 차원에 대한 차원 추가\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return self.dense_last(x)\n",
    "\n",
    "\n",
    "def model_fnn(input_witdh):\n",
    "    model = FNN()\n",
    "    model.build((None, input_witdh))\n",
    "    return model\n",
    "\n",
    "def model_custom(input_width):\n",
    "    model = CustomCNN()\n",
    "    model.build((None, input_width))\n",
    "    return model\n",
    "\n",
    "def model_resnet(input_width,layer_depth):\n",
    "    # 사전 훈련된 EfficientNetB2 모델 로드\n",
    "    base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(input_width, input_width, 3))\n",
    "\n",
    "    total_layers = len(base_model.layers)\n",
    "    trainable_layers = int(total_layers * layer_depth)  # 하위 j만 훈련\n",
    "\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 커스텀 층 추가\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)  # 배치 정규화 추가\n",
    "    x = Dropout(0.2)(x)  # 드롭아웃 추가\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)  # 다중 클래스 분류를 위한 설정\n",
    "\n",
    "    # 새로운 모델 정의\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_efficientnet(input_width,layer_depth):\n",
    "    # 사전 훈련된 EfficientNetB2 모델 로드\n",
    "    base_model = LayerApp.EfficientNetV2M(include_top=False, weights=\"imagenet\", input_shape=(input_width, input_width, 3))\n",
    "\n",
    "    total_layers = len(base_model.layers)\n",
    "    trainable_layers = int(total_layers * layer_depth)  # 전체가 1일 때, layer_depth만큼 ratio에 대해 학습\n",
    "\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 커스텀 층 추가\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)  # 배치 정규화 추가\n",
    "    x = Dropout(0.4)(x)  # 드롭아웃 추가\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)  # 다중 클래스 분류를 위한 설정\n",
    "\n",
    "    # 새로운 모델 정의\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "model1 = FNN()\n",
    "model1.summary()\n",
    "# visualkeras.layered_view(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "untitled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
