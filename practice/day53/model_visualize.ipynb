{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seunghwan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer \"dense_8\" has never been called and thus has no defined output shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 135\u001b[0m\n\u001b[0;32m    133\u001b[0m model1 \u001b[38;5;241m=\u001b[39m model_fnn(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# model1.summary()\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m \u001b[43mvisualkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayered_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kth53\\anaconda3\\envs\\untitled\\lib\\site-packages\\visualkeras\\layered.py:85\u001b[0m, in \u001b[0;36mlayered_view\u001b[1;34m(model, to_file, min_z, min_xy, max_z, max_xy, scale_z, scale_xy, type_ignore, index_ignore, color_map, one_dim_orientation, background_fill, draw_volume, padding, spacing, draw_funnel, shade_step, legend, font, font_color)\u001b[0m\n\u001b[0;32m     82\u001b[0m y \u001b[38;5;241m=\u001b[39m min_xy\n\u001b[0;32m     83\u001b[0m z \u001b[38;5;241m=\u001b[39m min_z\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_shape\u001b[49m, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m     86\u001b[0m     shape \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39moutput_shape\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer\u001b[38;5;241m.\u001b[39moutput_shape, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m     88\u001b[0m         layer\u001b[38;5;241m.\u001b[39moutput_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# drop dimension for non seq. models\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kth53\\anaconda3\\envs\\untitled\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:2182\u001b[0m, in \u001b[0;36mLayer.output_shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2168\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the output shape(s) of a layer.\u001b[39;00m\n\u001b[0;32m   2169\u001b[0m \n\u001b[0;32m   2170\u001b[0m \u001b[38;5;124;03mOnly applicable if the layer has one output,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2179\u001b[0m \u001b[38;5;124;03m    RuntimeError: if called in Eager mode.\u001b[39;00m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m-> 2182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2183\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined output shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2185\u001b[0m     )\n\u001b[0;32m   2186\u001b[0m all_output_shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[0;32m   2187\u001b[0m     [\u001b[38;5;28mstr\u001b[39m(node\u001b[38;5;241m.\u001b[39moutput_shapes) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes]\n\u001b[0;32m   2188\u001b[0m )\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_output_shapes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer \"dense_8\" has never been called and thus has no defined output shape."
     ]
    }
   ],
   "source": [
    "import visualkeras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications as LayerApp\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import absl.logging\n",
    "\n",
    "class CustomCNN(Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Add L2 regularization to the convolutional layers\n",
    "        #self.conv1 = Conv1D(32, 3, activation='relu', padding='same', kernel_regularizer=l2(0.00001))\n",
    "        self.conv1 = Conv1D(32, 3, activation='relu', padding='same')\n",
    "        #self.bn1 = BatchNormalization()\n",
    "        self.pool1 = MaxPooling1D(2)\n",
    "        #self.dropout1 = Dropout(0.2)\n",
    "\n",
    "        #self.conv2 = Conv1D(64, 3, activation='relu', padding='same', kernel_regularizer=l2(0.00001))\n",
    "        self.conv2 = Conv1D(64, 3, activation='relu', padding='same')\n",
    "        #self.bn2 = BatchNormalization()\n",
    "        #self.pool2 = MaxPooling1D(2)\n",
    "        #self.dropout2 = Dropout(0.2)\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(256, activation='relu')\n",
    "        self.dropout3 = Dropout(0.2)\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dense3 = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # 시퀀스 길이 대신 특징 차원에 대한 차원 추가\n",
    "        inputs = tf.expand_dims(inputs, axis=-1)\n",
    "        x = self.conv1(inputs)\n",
    "        #x = self.bn1(x, training=training)\n",
    "        x = self.pool1(x)\n",
    "        #x = self.dropout1(x, training=training)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        #x = self.bn2(x, training=training)\n",
    "        #x = self.pool2(x)\n",
    "        #x = self.dropout2(x, training=training)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout3(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "class FNN(Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(FNN, self).__init__()\n",
    "        self.dense1 = Dense(256, activation='relu')\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dense3 = Dense(256, activation='relu')\n",
    "        self.dense_last = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # 시퀀스 길이 대신 특징 차원에 대한 차원 추가\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return self.dense_last(x)\n",
    "\n",
    "\n",
    "def model_fnn(input_witdh):\n",
    "    model = FNN()\n",
    "    model.build((None, input_witdh))\n",
    "    return model\n",
    "\n",
    "def model_custom(input_width):\n",
    "    model = CustomCNN()\n",
    "    model.build((None, input_width))\n",
    "    return model\n",
    "\n",
    "def model_resnet(input_width,layer_depth):\n",
    "    # 사전 훈련된 EfficientNetB2 모델 로드\n",
    "    base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(input_width, input_width, 3))\n",
    "\n",
    "    total_layers = len(base_model.layers)\n",
    "    trainable_layers = int(total_layers * layer_depth)  # 하위 j만 훈련\n",
    "\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 커스텀 층 추가\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)  # 배치 정규화 추가\n",
    "    x = Dropout(0.2)(x)  # 드롭아웃 추가\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)  # 다중 클래스 분류를 위한 설정\n",
    "\n",
    "    # 새로운 모델 정의\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_efficientnet(input_width,layer_depth):\n",
    "    # 사전 훈련된 EfficientNetB2 모델 로드\n",
    "    base_model = LayerApp.EfficientNetV2M(include_top=False, weights=\"imagenet\", input_shape=(input_width, input_width, 3))\n",
    "\n",
    "    total_layers = len(base_model.layers)\n",
    "    trainable_layers = int(total_layers * layer_depth)  # 전체가 1일 때, layer_depth만큼 ratio에 대해 학습\n",
    "\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 커스텀 층 추가\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)  # 배치 정규화 추가\n",
    "    x = Dropout(0.4)(x)  # 드롭아웃 추가\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)  # 다중 클래스 분류를 위한 설정\n",
    "\n",
    "    # 새로운 모델 정의\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "model1 = model_fnn(2)\n",
    "# model1.summary()\n",
    "visualkeras.layered_view(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sewoon NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNetClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(\n",
    "            64 * 8 * 8, 512\n",
    "        )  # 이미지 크기가 32x32이므로 최종 feature map 크기는 8x8입니다.\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the feature maps\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvNetClassifier(num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "untitled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
